{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 трансформер для перевода с немецкого на английский"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня вы поработаете над настоящей задачей NLP и попробуете обучить трансформер переводить короткие предложения с английского на немецкий.\n",
    "\n",
    "Токенизацию и блоки трансформера писать не придётся — будем пользоваться библиотекой `transformers`.\n",
    "\n",
    "Наши задачи:\n",
    "- Познакомиться с наиболее популярным методом токенизации текстов — byte pair encoding\n",
    "- Научиться пользоваться токенизатором из `transformers`\n",
    "- Подготовить даннные\n",
    "- Обучить готовую архитектуру T5-small под нашу задачу\n",
    "- Исследовать разные стратегии декодирования с помощью обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e5641b53770>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
    "test_dataset = load_dataset(\"bentrevett/multi30k\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def length_histogram(dataset, ax, bins=20) -> None:\n",
    "    en_lengths = []\n",
    "    de_lengths = []\n",
    "    for sample in dataset:\n",
    "        en_lengths.append(len(sample[\"en\"].split(\" \")))\n",
    "        de_lengths.append(len(sample[\"de\"].split(\" \")))\n",
    "\n",
    "    ax.hist(en_lengths, alpha=0.5, bins=bins, label=\"en\")\n",
    "    ax.hist(de_lengths, alpha=0.5, bins=bins, label=\"de\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "length_histogram(train_dataset, axes[0])\n",
    "length_histogram(test_dataset, axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только сравнительно короткие предложения, чтобы можно было чему-то научиться за короткое время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5144 174\n"
     ]
    }
   ],
   "source": [
    "maxlen = 8\n",
    "\n",
    "def filter_dataset(dataset, maxlen: int) -> list[dict[str, str]]:\n",
    "    return [\n",
    "        dataset[i]\n",
    "        for i in range(len(dataset))\n",
    "        if len(dataset[i][\"en\"].split(\" \")) <= maxlen\n",
    "    ]\n",
    "\n",
    "\n",
    "train_filtered = filter_dataset(train_dataset, maxlen)\n",
    "test_filtered = filter_dataset(test_dataset, maxlen)\n",
    "\n",
    "print(len(train_filtered), len(test_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Токенизация: byte-pair encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение:\n",
    "\n",
    "Начинаем со словаря, состоящего из отдельных символов (начальные токены).\n",
    "На каждом шаге:\n",
    "1. Оцениваем частоту всех пар токенов внутри слов, находим самую частую\n",
    "2. Добавляем её в список токенов и в таблицу слияний\n",
    "3. Останавливаемся, когда достигаем максимального размера словаря\n",
    "\n",
    "\n",
    "Применение:\n",
    "\n",
    "1. Разбиваем текст на символы\n",
    "2. Находим первое возможное слияние в таблице и применяем его\n",
    "3. Останавливаемся, когда дальнейшие слияния невозможны\n",
    "\n",
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/bpe/build_merge_table.gif\" style=\"background:white\" height=\"300\"/>\n",
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/bpe/bpe_apply.gif\" style=\"background:white\" height=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализаций много, мы будем использовать токенизатор  из библиотеки `transformers`, где помимо самого подготовленного токенизатора (`sentencepiece.SentencePieceProcessor`) много полезных методов для кодирования и декодирования.\n",
    "\n",
    "Добавим при создании новый токен, который будет указывать на начало перевода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(\n",
    "    \"t5-small\", padding_size=\"right\", bos_token=\"</b>\", legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря:  32101\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер словаря: \", len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примеры токенов, в них встречаются и целые слова из разных языков, и числительные, и знаки препинания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HY', 15761),\n",
       " ('▁Pres', 10131),\n",
       " ('▁après', 3308),\n",
       " ('▁Berater', 30294),\n",
       " ('buch', 5671),\n",
       " ('ständ', 17955),\n",
       " ('▁Kentucky', 13401),\n",
       " ('datele', 12918),\n",
       " ('WOOD', 29637),\n",
       " ('vapeur', 30951)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choices(list(tokenizer.get_vocab().items()), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор в работе: кодирование и декодирование предложений на немецком и английском:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11280, 16815, 7838, 15, 16282, 436, 256, 8671, 35, 16, 74, 13271, 2221, 49, 21162, 3992, 5, 1]\n",
      "Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.</s>\n",
      "[2759, 1021, 6, 1945, 5069, 7, 33, 1067, 1084, 186, 3, 30271, 5, 1]\n",
      "Two young, White males are outside near many bushes.</s>\n"
     ]
    }
   ],
   "source": [
    "encoded_german = tokenizer.encode(train_dataset[0][\"de\"])\n",
    "encoded_english = tokenizer.encode(train_dataset[0][\"en\"])\n",
    "print(encoded_german)\n",
    "print(tokenizer.decode(encoded_german))\n",
    "print(encoded_english)\n",
    "print(tokenizer.decode(encoded_english))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Об упаковке в батчи можно больше не беспокоиться — токенизатор умеет обрабатывать сразу пачку примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 19])\n",
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "batch = [train_dataset[i][\"en\"] for i in range(4)]\n",
    "\n",
    "encoded_batch = tokenizer.batch_encode_plus(\n",
    "    batch, padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_batch[\"input_ids\"].shape)\n",
    "print(encoded_batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возвращается два значения: `input_ids` — это наши токены, а `attention_mask` — это тензор, равный по размеру батчу токенов, где на месте `pad_token` стоят нули, в остальных позициях — единицы. Это нам понадобится потом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А ещё можно кодировать сразу входные и выходные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "inputs = [train_dataset[i][\"en\"] + tokenizer.bos_token for i in range(4)]\n",
    "targets = [train_dataset[i][\"de\"] for i in range(4)]\n",
    "\n",
    "encoded_batch = tokenizer(\n",
    "    inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем это в `collate_fn` для сборки батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(\n",
    "    tokenizer: T5Tokenizer, batch: list[tuple[str, str]]\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    prompt =tokenizer.bos_token\n",
    "    inputs, targets = zip(*[(pair[\"de\"], prompt + pair[\"en\"]) for pair in batch])\n",
    "    encoded_batch = tokenizer(\n",
    "        inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )\n",
    "    return encoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "batch = [train_dataset[i] for i in range(4)]\n",
    "encoded_batch = collate_fn(tokenizer, batch)\n",
    "print(encoded_batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 22])\n",
      "torch.Size([4, 22])\n",
      "torch.Size([4, 20])\n"
     ]
    }
   ],
   "source": [
    "print(encoded_batch[\"input_ids\"].shape)\n",
    "print(encoded_batch[\"attention_mask\"].shape)\n",
    "print(encoded_batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё готово для получения минибатчей из датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_filtered,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_filtered,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")\n",
    "\n",
    "train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
    "test_dataset = load_dataset(\"bentrevett/multi30k\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1 (3 балла). DataModule\n",
    "\n",
    "Реализуйте подкласс `lightning.LightningDataModule` для работы с обучающим и тестовым датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "\n",
    "\n",
    "class Multi30kDataset(L.LightningDataModule):\n",
    "    train_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "    tokenizer: T5Tokenizer\n",
    "\n",
    "    def __init__(self, maxlen: int = 0, batch_size: int = 32, tokenizer: T5Tokenizer = tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.maxlen = maxlen\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = train_dataset\n",
    "        elif stage == \"validate\":\n",
    "            self.test_dataset = test_dataset\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "   filter_dataset(self.train_dataset, self.maxlen),\n",
    "    batch_size=self.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(filter_dataset(self.test_dataset, self.maxlen),\n",
    "        batch_size=self.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda batch: collate_fn(self.tokenizer, batch),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi30k = Multi30kDataset(maxlen=8, tokenizer=tokenizer, batch_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2 (6 баллов). Обучение T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: https://arxiv.org/abs/1910.10683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите `t5-small` на наших данных, длительность обучения — на ваше усмотрение. В [документации](https://huggingface.co/docs/transformers/model_doc/t5) вы найдёте примеры использования, которые помогут вам разобраться в интерфейсе модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обернём в `LightningModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "\n",
    "\n",
    "class Seq2Seq(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        lr: float = 0.01,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lr = lr\n",
    "        \n",
    "    def training_step(self, batch: dict[str, Tensor], batch_idx: int) -> STEP_OUTPUT:\n",
    "        loss = self.model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"labels\"]).loss\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return torch.optim.Adam(self.parameters(), self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sachaiugai/anaconda3/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/sachaiugai/Документы/Jupiter_projects/dnn-mkn-7/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M | train\n",
      "-------------------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "277       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/sachaiugai/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb303cda0344a52b9d1a160cd8a2b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\", max_epochs=1, limit_train_batches=10, logger=False\n",
    ")\n",
    "seq2seq = Seq2Seq(t5, multi30k.tokenizer, lr=0.001)\n",
    "seq2seq.train()\n",
    "trainer.fit(model=seq2seq, datamodule=multi30k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3 (3 балла). Генерация перевода\n",
    "\n",
    "Сгенерируйте перевод для одного батча из тестового датасета (используйте метод `t5.generate()`), используя разные стратегии декодирования:\n",
    "- *greedy decoding*\n",
    "- *multinomial sampling*\n",
    "- *beam-search multinomial sampling*\n",
    "\n",
    "Эти стратегии (а также другие стратегии декодирования) можно задавать через `transformers.GenerationConfig`, который можно передать в метод `.generate()` нашей модели.\n",
    "Выберите параметры, которые, на ваш взгляд, работают лучше всего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# пример конфигурации\n",
    "gen_conf = GenerationConfig(\n",
    "    min_length=10,\n",
    "    max_new_tokens=20,\n",
    "    num_beams=5,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_p=0.9,\n",
    "    top_k=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy decoding\n",
    "gen_conf_greedy_decoding = GenerationConfig(\n",
    "    min_length=10,\n",
    "    max_new_tokens=20,\n",
    ")\n",
    "\n",
    "# multinomial sampling\n",
    "gen_conf_multinomial_sampling = GenerationConfig(\n",
    "    min_length=10,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# beam-search multinomial sampling\n",
    "gen_conf_beam_search_multinomial_sampling = GenerationConfig(\n",
    "    min_length=10,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    num_beams=5\n",
    ")\n",
    "\n",
    "# my_gen_config\n",
    "my_gen_conf = GenerationConfig(\n",
    "    min_length=10,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    no_repeat_ngram_size=2\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutsch: Leute Reparieren das Dach eines Hauses.\n",
      "English: People are fixing the roof of a house.\n",
      "Translation(greedy decoding): people are rearranging the roof..\n",
      "Translation(multinomial sampling): People in a home.com Leute who are looking for the\n",
      "Translation(beam-search multinomial sampling): Menschen reparieren das Dach eines Hauses.\n",
      "Translation(my): People doing the same thing in homes.com.\n",
      "\n",
      "Deutsch: Ein Typ arbeitet an einem Gebäude.\n",
      "English: A guy works on a building.\n",
      "Translation(greedy decoding): Ein Typ arbeitet in a building.Important An individual is working on a building\n",
      "Translation(multinomial sampling): A type works on a building.\n",
      "Translation(beam-search multinomial sampling): A type of building.\n",
      "Translation(my): The Typ works in a building..\n",
      "\n",
      "Deutsch: Drei Leute sitzen in einer Höhle.\n",
      "English: Three people sit in a cave.\n",
      "Translation(greedy decoding): \n",
      "Translation(multinomial sampling): Sitting three people in a window.\n",
      "Translation(beam-search multinomial sampling): Drei Leute sitzen in a Höhle.\n",
      "Translation(my): In a dark room, people are sitting in höhle.\n",
      "\n",
      "Deutsch: Leute, die vor einem Gebäude stehen.\n",
      "English: People standing outside of a building.\n",
      "Translation(greedy decoding): people who are in a building.  Leute\n",
      "Translation(multinomial sampling): people, in a building. a man, and\n",
      "Translation(beam-search multinomial sampling): Menschen, die vor einem Gebäude stehen. Leute, die vor einem Gebäude\n",
      "Translation(my): People, the people who are standing in front of a building.\n",
      "\n",
      "Deutsch: Ein Mann schneidet ste von Bäumen.\n",
      "English: A man cutting branches of trees.\n",
      "Translation(greedy decoding): Ein Mann schneidetnga ste of trees\n",
      "Translation(multinomial sampling): A man holding a tree.\n",
      "Translation(beam-search multinomial sampling): Ein Mann schneidet ste von Bäumen.\n",
      "Translation(my): A man who is in the trees.\n",
      "\n",
      "Deutsch: Frauen, die traditionelle Kleidung tragen, spielen das Leben Einheimischer nach.\n",
      "English: Women, wearing traditional clothing, are reenacting native life.\n",
      "Translation(greedy decoding): women, the traditionelle clothing worn by women, playing the life of a man\n",
      "Translation(multinomial sampling): Frauen wearing traditional clothing play the life. The girls are dressed up in the closet.\n",
      "Translation(beam-search multinomial sampling): Frauen, die traditionelle Kleidung, spielen das Leben Einheimischer nach.\n",
      "Translation(my): Women are wearing traditional clothing, a home tucking and dressing in the room.\n",
      "\n",
      "Deutsch: Ein Kind planscht im Wasser.\n",
      "English: A child is splashing in the water\n",
      "Translation(greedy decoding): A child plans to swim in water. Ein kind of\n",
      "Translation(multinomial sampling): Dien einen eenplanacht in Wasser.\n",
      "Translation(beam-search multinomial sampling): The child plans to swim in water..\n",
      "Translation(my): salopes are a baby planningte in water.\n",
      "\n",
      "Deutsch: Eine schöne Frau spielt auf einer Harfe.\n",
      "English: A pretty woman plays a harpsichord.\n",
      "Translation(greedy decoding): Une belle Fraudinga a woman.\n",
      "Translation(multinomial sampling): One smiling woman playing in a hare.\n",
      "Translation(beam-search multinomial sampling): Eine schöne Frau spielt spielt auf a dog.\n",
      "Translation(my): Eine schöne Frau spielt in a chair.\n",
      "\n",
      "Deutsch: Die junge Dame sieht auf die Pizza.\n",
      "English: The young lady is looking at the pizza.\n",
      "Translation(greedy decoding): The young lady looks on the pizza.\n",
      "Translation(multinomial sampling): Die junge Dame sieht auf die Pizza.\n",
      "Translation(beam-search multinomial sampling): a young lady is dressed in a pizza.\n",
      "Translation(my): Ein jungesDamedall hat diesse in a pizza.\n",
      "\n",
      "Deutsch: Leute sitzen in einem Zug.\n",
      "English: People sit inside a train.\n",
      "Translation(greedy decoding): people sitting in a train.  people sitting in\n",
      "Translation(multinomial sampling): Leute sitzen in a cab.\n",
      "Translation(beam-search multinomial sampling): Menschen in a Zug sitzen in a train.\n",
      "Translation(my): people sitting in a Zug.com.\n",
      "\n",
      "Deutsch: Ein kleines Kind kocht mit einer anderen Person.\n",
      "English: A toddler is cooking with another person.\n",
      "Translation(greedy decoding): La petite petite personne s'enrône dans un autre endroit.\n",
      "Translation(multinomial sampling): Die kleine Kindkocht mit einer anderen Person.\n",
      "Translation(beam-search multinomial sampling): A small kid kocht with another person.\n",
      "Translation(my): Es a small girl cooks with another person.\n",
      "\n",
      "Deutsch: Ein Mann bereitet am Herd Essen zu.\n",
      "English: A man cooking food on the stove.\n",
      "Translation(greedy decoding): A man is prepared to greet the woman holding herd's food.\n",
      "Translation(multinomial sampling): Ein Mann bereitet am Herd Essen zu.\n",
      "Translation(beam-search multinomial sampling): Ein Mann bereitet am Herd Essen zu.\n",
      "Translation(my): Ein Mann is prepared to go to the Herd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(multi30k.test_dataloader()))\n",
    "preds1 = t5.generate(batch[\"input_ids\"], generation_config=gen_conf_greedy_decoding)\n",
    "preds2 = t5.generate(batch[\"input_ids\"], generation_config=gen_conf_multinomial_sampling)\n",
    "preds3 = t5.generate(batch[\"input_ids\"], generation_config=gen_conf_beam_search_multinomial_sampling)\n",
    "preds4 = t5.generate(batch[\"input_ids\"], generation_config=my_gen_conf)\n",
    "\n",
    "for i in range(multi30k.batch_size):\n",
    "# декодируем входы, правильный и сгенерированный перевод с помощью токенизатора и выводим\n",
    "    print(f\"Deutsch: {tokenizer.decode(batch[\"input_ids\"][i], skip_special_tokens=True)}\")\n",
    "    print(f\"English: {tokenizer.decode(batch[\"labels\"][i], skip_special_tokens=True)}\")\n",
    "    print(f\"Translation(greedy decoding): {tokenizer.decode(preds1[i], skip_special_tokens=True)}\")\n",
    "    print(f\"Translation(multinomial sampling): {tokenizer.decode(preds2[i], skip_special_tokens=True)}\")\n",
    "    print(f\"Translation(beam-search multinomial sampling): {tokenizer.decode(preds3[i], skip_special_tokens=True)}\")\n",
    "    print(f\"Translation(my): {tokenizer.decode(preds4[i], skip_special_tokens=True)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
